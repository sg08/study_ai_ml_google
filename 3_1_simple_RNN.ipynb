{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "3_1_simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b462010-d9eb-4159-be58-7a6b1b1c780c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feXB1SiLP4OL"
      },
      "source": [
        "# simple RNN\n",
        "### バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tzSWNYwxP4OM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dae0b6fc-0ed6-4aef-92ce-f8c2c821aaaf"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:0.8552922918710246\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "11 + 52 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.7445483269958576\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "70 + 120 = 239\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.8860925218578657\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "105 + 101 = 218\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.1138523882941238\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 1 0 1]\n",
            "113 + 116 = 130\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.041361608268851\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "43 + 69 = 2\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8372108798906186\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "2 + 26 = 52\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.2699089634921377\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "69 + 123 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.939796825000861\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "61 + 121 = 246\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.1062775712639152\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "93 + 42 = 254\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8444812892714983\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "56 + 72 = 80\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0808040356535553\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "126 + 82 = 252\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8976819507011774\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "11 + 33 = 15\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0210369186652717\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "27 + 40 = 50\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8659950998654212\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "42 + 65 = 77\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7679400863066556\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "70 + 3 = 13\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8033142649971526\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "9 + 81 = 94\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8634606436510404\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "103 + 36 = 75\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.7160255165801918\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 1 0 1 1 0 1 0]\n",
            "116 + 102 = 138\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.138938968201587\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "59 + 45 = 86\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.8374657628424084\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "23 + 67 = 92\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8436029865416746\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "5 + 28 = 57\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.8379669754158308\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "60 + 68 = 72\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.2061278359854728\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "59 + 125 = 254\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.5954945989011255\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "52 + 68 = 88\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.6582397234972782\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "57 + 8 = 81\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.40717336326541254\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "65 + 39 = 104\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.6066745616503431\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "9 + 123 = 148\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.25856616778252695\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "55 + 36 = 91\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.4084275286295067\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "120 + 17 = 137\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.22816263964662734\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "40 + 68 = 108\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.36927540904652273\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "92 + 12 = 104\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.2063544985363946\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "105 + 43 = 148\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.1661121358252357\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "45 + 36 = 81\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.29884750173399244\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "122 + 103 = 225\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.24557240829789403\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "100 + 99 = 199\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.9656553889355457\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "76 + 3 = 83\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.08959525373875797\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "126 + 20 = 146\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.06743243337464444\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "49 + 70 = 119\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.25281252068722465\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "78 + 9 = 83\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.2232105562767478\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "39 + 21 = 60\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.08367242469081355\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "36 + 110 = 146\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.05764894727212863\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "12 + 85 = 97\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.0902841920349329\n",
            "Pred:[1 1 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "124 + 76 = 200\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.05338394564771442\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "65 + 46 = 111\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.037700883356868574\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "36 + 104 = 140\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.06627525429613185\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "116 + 30 = 146\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.0364958039462958\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "96 + 111 = 207\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.04212849438480347\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "30 + 94 = 124\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.026959332609408915\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "110 + 102 = 212\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.012610935773189993\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "8 + 97 = 105\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.009163066028158338\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "66 + 0 = 66\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.009818073948449241\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "106 + 4 = 110\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.008856052143967933\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "19 + 85 = 104\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.021742254813629378\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "118 + 41 = 159\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.014363258208455507\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "98 + 105 = 203\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.017270862976758783\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "25 + 123 = 148\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.0127593931147983\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "112 + 27 = 139\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.007854406486448582\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "92 + 1 = 93\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.007116415757280465\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "92 + 96 = 188\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.009124609581697616\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "93 + 97 = 190\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.007667338812599126\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "92 + 18 = 110\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.02114388850346555\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "55 + 91 = 146\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.006273840890706724\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "104 + 70 = 174\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.019170653408631902\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "89 + 55 = 144\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.008687509817684232\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "43 + 77 = 120\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.009843765021150194\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "23 + 51 = 74\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.004690448895165736\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "36 + 7 = 43\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.006582758274185439\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "36 + 78 = 114\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.006145843636598257\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "114 + 42 = 156\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.002947087156284858\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "113 + 70 = 183\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.007323230775996526\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "94 + 4 = 98\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.004060544722550642\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "80 + 27 = 107\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.004892236062357876\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "93 + 112 = 205\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.008319967797266683\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "127 + 87 = 214\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0034396724347869156\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "75 + 100 = 175\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.007835781987753733\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "42 + 119 = 161\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.006037195926690192\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "127 + 19 = 146\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.002908626095859805\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "25 + 24 = 49\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.006656990648756574\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "73 + 59 = 132\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.0038034221030027577\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "69 + 79 = 148\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0028965798123496184\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "16 + 15 = 31\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.002521992483033767\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "25 + 74 = 99\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.003964373146494996\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "95 + 46 = 141\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.00242437026504995\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "53 + 120 = 173\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0008414769351317213\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "45 + 69 = 114\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.005956343787792262\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "31 + 111 = 142\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0016256729062994236\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "80 + 37 = 117\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0022323971738028234\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "49 + 60 = 109\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.004170969776880939\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "95 + 115 = 210\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.00239354955431045\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "92 + 80 = 172\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0028134061885831483\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "119 + 88 = 207\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.002316483250885235\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "53 + 58 = 111\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.002690421105606701\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "114 + 120 = 234\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0021546334098006942\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "43 + 100 = 143\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0010066439809995455\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "91 + 89 = 180\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.001169531616118808\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "13 + 16 = 29\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0017089010886748653\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "29 + 24 = 53\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0013259479284217668\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "54 + 19 = 73\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0015859655756122635\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "18 + 49 = 67\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0011254533541139092\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "41 + 121 = 162\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7zQEPrtP4OP"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
        " * 2, 0.01, 32 に変更\n",
        "\n",
        "## [try] 重みの初期化方法を変更してみよう\n",
        "Xavier, He\n",
        "\n",
        "## [try] 中間層の活性化関数を変更してみよう\n",
        "ReLU(勾配爆発を確認しよう)<br>\n",
        "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SxvbtBggLohg",
        "outputId": "6e849997-f18c-4ce3-89df-24bb3d178634"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 32\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 2\n",
        "learning_rate = 0.01\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.82518805710248\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "35 + 16 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.250478668434633\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "84 + 109 = 253\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.1231788034562589\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 1 0 1 0 1 0 1]\n",
            "97 + 116 = 201\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.123059629320114\n",
            "Pred:[1 1 1 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "13 + 70 = 241\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.210538814874301\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "15 + 23 = 33\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.37701419811120807\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "118 + 5 = 59\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.682498615471819\n",
            "Pred:[0 0 1 1 1 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "45 + 40 = 61\n",
            "------------\n",
            "iters:700\n",
            "Loss:2.1711241485743047\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "58 + 36 = 33\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0524226704234798\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "25 + 14 = 29\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.152606313408475\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "111 + 54 = 99\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0635733051817011\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "87 + 117 = 122\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9155197214264768\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "79 + 64 = 93\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8600839489539591\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "27 + 26 = 31\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0708619406845232\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "57 + 71 = 250\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7769499136240955\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "72 + 45 = 121\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8988384140460327\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "66 + 111 = 107\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.5267391049346455\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "106 + 40 = 121\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.8744731207356358\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "51 + 63 = 2\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.403506980625173\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "82 + 62 = 127\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.5232231716395432\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "3 + 41 = 36\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.9125095387427831\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "23 + 55 = 58\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.8488811456240557\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "78 + 105 = 111\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.6970173282867811\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "10 + 47 = 43\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.1764707782512955\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "56 + 119 = 249\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.1666906171182796\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "42 + 43 = 43\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.261416628399007\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "99 + 80 = 127\n",
            "------------\n",
            "iters:2600\n",
            "Loss:1.2264161134878195\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[1 1 1 0 1 0 0 0]\n",
            "120 + 112 = 109\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.972059007981236\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 0 0 0 1]\n",
            "1 + 16 = 29\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.824955667100105\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "37 + 98 = 71\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.173614081831877\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "34 + 40 = 41\n",
            "------------\n",
            "iters:3000\n",
            "Loss:1.033518464574777\n",
            "Pred:[0 0 0 0 1 0 1 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "78 + 15 = 11\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.8459563274871531\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "49 + 42 = 63\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.8532685507388013\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "45 + 76 = 65\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.177837287547083\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "96 + 96 = 13\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.9798149022536189\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "84 + 27 = 89\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.9249917425895775\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "27 + 52 = 53\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.9388803694422984\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "9 + 127 = 96\n",
            "------------\n",
            "iters:3700\n",
            "Loss:1.0343982380089156\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "124 + 75 = 121\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.8329251952858718\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "84 + 69 = 93\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.8230301597057551\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "7 + 106 = 107\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.9955398072213236\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "77 + 49 = 56\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.5960505674377724\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "5 + 106 = 111\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.9519839197090438\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "18 + 117 = 127\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.8767489027742097\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[1 1 1 0 1 0 1 1]\n",
            "119 + 116 = 115\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.6264400051134285\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "24 + 69 = 93\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.9928655834314392\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "28 + 99 = 97\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.6170051962520968\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "69 + 54 = 123\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.801138731120073\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "75 + 45 = 108\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.8349533674252104\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "122 + 21 = 127\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.9623269908664092\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "50 + 127 = 123\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.8278130628672015\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[1 1 1 0 1 0 1 1]\n",
            "125 + 110 = 115\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.8583433581134735\n",
            "Pred:[0 0 0 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "99 + 69 = 12\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.8523300553907289\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "37 + 118 = 123\n",
            "------------\n",
            "iters:5300\n",
            "Loss:1.1687136150490611\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "70 + 64 = 74\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.5724022104797265\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "0 + 37 = 45\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.9770818896732016\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "29 + 47 = 58\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.8161045841267324\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "41 + 71 = 72\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.7814826151524651\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "117 + 90 = 255\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.6682715661441758\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "37 + 0 = 45\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.872713351323653\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "65 + 29 = 28\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.6794259361012687\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "33 + 7 = 46\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.6215187883035838\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "11 + 77 = 92\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.9787990981848793\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "80 + 82 = 86\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.7813870377519794\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "25 + 62 = 47\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.8010655999805842\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "1 + 111 = 96\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.9224653892477075\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "42 + 82 = 126\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.8121541497558775\n",
            "Pred:[1 1 0 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "100 + 70 = 206\n",
            "------------\n",
            "iters:6700\n",
            "Loss:1.026839106458878\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "39 + 104 = 123\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.6850967601629642\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "39 + 37 = 40\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.8239718148693289\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "4 + 112 = 120\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.668440587207362\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "48 + 4 = 124\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.9041293827838832\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "101 + 5 = 76\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.9594258861997584\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "115 + 18 = 247\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.7884331755860946\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "43 + 78 = 117\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.7722282266224796\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "74 + 9 = 31\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.6684231121674868\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "35 + 3 = 2\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.7086971941830741\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "69 + 54 = 251\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.7214441884167488\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "48 + 60 = 68\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.8447476728182692\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "98 + 47 = 251\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.6809356367411119\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "61 + 66 = 119\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.6973747447541456\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "70 + 68 = 66\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.7254551986228635\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "13 + 84 = 81\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.7042098808228916\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "53 + 24 = 101\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.6819170924484002\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "12 + 51 = 57\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.6218624862396841\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "0 + 109 = 125\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.9059052437320791\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "69 + 69 = 76\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.6911136906658494\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "96 + 4 = 76\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.3337718949322845\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 0 0 0 1 0 0 0]\n",
            "7 + 1 = 8\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.9304217687347782\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "52 + 86 = 126\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.9059533202673337\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "63 + 105 = 124\n",
            "------------\n",
            "iters:9000\n",
            "Loss:1.1052246747757402\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "109 + 29 = 212\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.8714741322613625\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "69 + 62 = 251\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.9770456212429096\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "74 + 126 = 162\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.8455374527131235\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "38 + 75 = 107\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.7269707001635753\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "5 + 47 = 34\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.7175144938966284\n",
            "Pred:[0 0 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "18 + 55 = 9\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.590646051485171\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "31 + 9 = 60\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.9215134136855744\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "109 + 87 = 146\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.5430863430690028\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "59 + 33 = 124\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.8071143251366837\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "110 + 91 = 129\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2SHYm5bLqDU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}